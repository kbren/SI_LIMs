{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy as spy\n",
    "import pickle \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "from collections import OrderedDict \n",
    "\n",
    "import time as timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/\")\n",
    "import LIM_utils as lim\n",
    "\n",
    "import LIM_utils_kb as limkb\n",
    "import LIM_stats_kb as statskb\n",
    "import LIM_plot_kb as plotkb\n",
    "import LIM_building as limbuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LIM_building' from '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIM_building.py'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(limkb)\n",
    "importlib.reload(statskb)\n",
    "importlib.reload(limbuild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_proj = dict(projection=ccrs.Stereographic(central_latitude=90,\n",
    "                                              central_longitude=-45,\n",
    "                                              true_scale_latitude=0.1))\n",
    "proj = dict(projection=ccrs.Robinson(central_longitude=0.),zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "#Year-month-day\n",
    "today_date = today.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train one month LIM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of EOFs to retain for the LIM state vector\n",
    "ntrunc = 30 # EOF truncation for individual fields (reduced-state space)\n",
    "nmodes = 30 # number of coupled EOFs for LIM state space (truncated-state space)\n",
    "#nmodes = 25\n",
    "nmodes_sic = 50\n",
    "#modes_sic = 20\n",
    "\n",
    "#mo='all'\n",
    "mo=4\n",
    "\n",
    "# forecast lead time in months that defines the LIM training\n",
    "tau = 1\n",
    "\n",
    "# training data defined by the first ntrain times\n",
    "# fraction of years used in training\n",
    "# ensures that start year of both train and validation data is january \n",
    "ntrain = 1\n",
    "ntraintimes = 1980\n",
    "# nvalidtimes = 1872\n",
    "nttrain_valid = 0\n",
    "tscut_era = False    # time start cut \n",
    "tecut_era = False       # time end cut \n",
    "\n",
    "tscut_sat = False    # time start cut \n",
    "tecut_sat = 0       # time end cut \n",
    "\n",
    "# variables to include in the LIM (note \"vars\" is a Python command)\n",
    "#limvars = ['tas','zg']\n",
    "#limvars = ['tas','rlut','zg']\n",
    "#limvars = ['tas','tos','psl','sic']\n",
    "limvars = ['sic']\n",
    "#limvars = ['tas','sic']\n",
    "#limvars = ['tas','sic','zg','psl','pr','tos']\n",
    "#limvars = ['tas','psl','tos','sit','sic']\n",
    "# limvars = ['tas','tos','psl','sit','sic']\n",
    "# limvars_nosic = ['tas','tos','psl','sit']\n",
    "#limvars = ['tas','tos','psl','sit','sic']\n",
    "#limvars = ['tas','tos','sic']\n",
    "#limvars_nosic = ['tas','tos']\n",
    "limvars_nosic = []\n",
    "nvars = len(limvars)\n",
    "\n",
    "# specify the model source \n",
    "#train_dsource = 'ccsm4_hist_kb'\n",
    "#train_dsource = 'mpi_hist_kb'\n",
    "#train_dsource = 'cmip6_cesm2_ssp585'\n",
    "#train_dsource = 'cmip6_mpi_hist'\n",
    "train_dsource = 'mpi_lm_kb'\n",
    "#train_dsource = 'era5'\n",
    "valid_dsource = 'era5'\n",
    "#valid_dsource = 'mpi_lm_kb'\n",
    "#valid_sat = 'satellite'\n",
    "#valid_dsource = 'ccsm4_lm_kb'\n",
    "#valid_dsource = 'cmip6_mpi_hist'\n",
    "\n",
    "sic_separate = True\n",
    "Insamp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with truncated training data: \n",
    "#mod_folder = 'truncated_model_data/last_millennium/'\n",
    "#mod_folder = 'truncated_model_data/'#+folder_add\n",
    "mod_folder = ''#+folder_add\n",
    "#mod_filename = '_ntrunc'+str(ntrunc)+'_month'+str(mo)+'_'+train_dsource+'_'+'ntrain_1850_2004_20210921.pkl'\n",
    "mod_filename = '_ntrunc'+str(ntrunc)+'_month'+str(mo)+'_'+train_dsource+'_grid05_ntrain_1979_2004_20210914.pkl'\n",
    "\n",
    "#mod_sic_filename = '_ntrunc'+str(nmodes_sic)+'_month'+str(mo)+'_'+train_dsource+'_ntrain_1850_2050_20210916.pkl'\n",
    "mod_sic_filename = '_ntrunc'+str(nmodes_sic)+'_month'+str(mo)+'_'+train_dsource+'_grid05_ntrain_1979_2004_20210921.pkl'\n",
    "#mod_sic_filename = '_ntrunc'+str(nmodes_sic)+'_month'+str(mo)+'_'+train_dsource+'_'+'ntrain_1850_2004_20210921.pkl'\n",
    "mod_sic_filename = '_ntrunc50_month4_mpi_lm_kb_ntrain_850_1833_20210921.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_setup = {}\n",
    "exp_setup['mo'] = mo\n",
    "if 'all' in str(mo): \n",
    "    exp_setup['ind_month_trunc'] = False\n",
    "else: \n",
    "    exp_setup['ind_month_trunc'] = True\n",
    "exp_setup['tau'] = tau\n",
    "exp_setup['ntrunc'] = ntrunc \n",
    "exp_setup['nmodes_sic'] = nmodes_sic\n",
    "exp_setup['limvars'] = limvars\n",
    "exp_setup['train_dsource'] = train_dsource\n",
    "exp_setup['valid_dsource'] = valid_dsource \n",
    "exp_setup['sic_separate'] = sic_separate\n",
    "exp_setup['Insamp'] = Insamp\n",
    "exp_setup['mod_folder'] = mod_folder\n",
    "exp_setup['mod_filename'] = mod_filename\n",
    "exp_setup['mod_sic_filename'] = mod_sic_filename\n",
    "exp_setup['Weight']=True\n",
    "# era5 settings: \n",
    "# exp_setup['nyearsvalid'] = 16\n",
    "# exp_setup['nyearstot'] = 42\n",
    "# exp_setup['nyears_startvalid'] = 26*12\n",
    "\n",
    "# Satellite settings: \n",
    "# exp_setup['nyearsvalid'] = 12\n",
    "# exp_setup['nyearstot'] = 38\n",
    "# exp_setup['nyears_startvalid'] = 26*12\n",
    "\n",
    "# Historical settings: \n",
    "# exp_setup['nyearsvalid'] = 11\n",
    "# exp_setup['nyearstot'] = 164\n",
    "# exp_setup['nyears_startvalid'] = 154*12\n",
    "\n",
    "# LM settings\n",
    "exp_setup['nyearsvalid'] = 16\n",
    "exp_setup['nyearstot'] = 1000\n",
    "exp_setup['nyears_startvalid'] = (1000-16)*12\n",
    "\n",
    "exp_setup['ntrain']=((exp_setup['nyearstot']*12)-(exp_setup['nyearsvalid'] *12))/(exp_setup['nyearstot']*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cc9c2ce5d26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimbuild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimkb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatskb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(rf)\n",
    "importlib.reload(limbuild)\n",
    "importlib.reload(limkb)\n",
    "importlib.reload(statskb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_forecast_model_data as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Ptrunc, _, E3, tot_var, \n",
    " tot_var_eig, W_all, \n",
    " standard_factor, \n",
    " nyears_train, var_dict] = load_training_data_truncated(exp_setup['limvars'], exp_setup['mod_folder'], \n",
    "                                                        exp_setup['mod_sic_filename'], \n",
    "                                                        exp_setup['mod_filename'], \n",
    "                                                        exp_setup['mo'],exp_setup['nyearstot'],\n",
    "                                                        exp_setup['nyearsvalid'],\n",
    "                                                        ind_month_trunc=exp_setup['ind_month_trunc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = limbuild.get_var_indices(exp_setup['limvars'], var_dict)\n",
    "\n",
    "ndof_all = limkb.count_ndof_all(exp_setup['limvars'], E3, sic_separate=exp_setup['sic_separate'])\n",
    "\n",
    "\n",
    "if len(exp_setup['limvars'])<=1:\n",
    "    print('Only one variable detected...')\n",
    "    Ptrunc_all = []\n",
    "    E3_all = []\n",
    "    Ptrunc_sic = Ptrunc['sic']\n",
    "    E_sic = E3['sic']\n",
    "\n",
    "    P_train = Ptrunc_sic\n",
    "else: \n",
    "    print('Multiple variables detected...')\n",
    "    [Ptrunc_all, E3_all, \n",
    "    Ptrunc_sic,E_sic] = limkb.stack_variable_eofs(exp_setup['limvars'], ndof_all, \n",
    "                                                  exp_setup['ntrunc'], Ptrunc, E3,var_dict,\n",
    "                                                  sic_separate=exp_setup['sic_separate'])\n",
    "\n",
    "    P_train = np.concatenate((Ptrunc_all, Ptrunc_sic),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN LIM: \n",
    "    #--------------------------------------------------\n",
    "\n",
    "nmo = int(P_train.shape[1]/nyears_train)\n",
    "# nmo = 2\n",
    "P_train_3d = np.reshape(P_train, (P_train.shape[0],nyears_train,nmo))\n",
    "\n",
    "if exp_setup['mo'] is 'all':\n",
    "    LIMd2, G2 = lim.LIM_train(exp_setup['tau'],P_train)\n",
    "    print('Training LIM with tau = '+str(exp_setup['tau']))\n",
    "else: \n",
    "    LIMd2, G2 = lim.LIM_train_flex(exp_setup['tau'],P_train_3d[:,:,0], P_train_3d[:,:,1])\n",
    "    print('Training LIM with tau = '+str(exp_setup['tau']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "\n",
    "max_eigenval = np.real(LIMd2['lam_L']).max()\n",
    "\n",
    "if max_eigenval >0: \n",
    "    LIMd2['lam_L_adj'] = LIMd2['lam_L'] - (max_eigenval+0.01)\n",
    "else: \n",
    "    LIMd2['lam_L_adj'] = LIMd2['lam_L']\n",
    "\n",
    "LIMd2['npos_eigenvalues'] = (LIMd2['lam_L']>0).sum()/(LIMd2['lam_L'].shape[0])\n",
    "print('Number of positive eigenvalues = '+ str((LIMd2['lam_L']>0).sum()/(LIMd2['lam_L'].shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_train_3d[3,:,0])\n",
    "plt.plot(P_train_3d[3,:,1])\n",
    "plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMd2['lam_L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LIM with LME: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/home/disk/chaos/mkb22/Documents/SeaIceData/LME/'\n",
    "#mnames = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "mnames = ['01','02']\n",
    "files_list = [dirname+'sic_global_'+i+'_CESM_CAM5_LME_085001-184912.nc' for i in mnames]\n",
    "\n",
    "limvars = ['sic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of EOFs to retain for the LIM state vector\n",
    "ntrunc = 30 # EOF truncation for individual fields (reduced-state space)\n",
    "nmodes = 30 # number of coupled EOFs for LIM state space (truncated-state space)\n",
    "#nmodes = 25\n",
    "nmodes_sic = 50\n",
    "#modes_sic = 20\n",
    "\n",
    "mo='all'\n",
    "#mo=0\n",
    "\n",
    "# forecast lead time in months that defines the LIM training\n",
    "tau = 1\n",
    "\n",
    "# training data defined by the first ntrain times\n",
    "# fraction of years used in training\n",
    "# ensures that start year of both train and validation data is january \n",
    "ntrain = 1\n",
    "ntraintimes = 1980\n",
    "# nvalidtimes = 1872\n",
    "nttrain_valid = 0\n",
    "tscut1 = False    # time start cut \n",
    "tecut1 = False       # time end cut \n",
    "\n",
    "tscut2 = False    # time start cut \n",
    "tecut2 = False       # time end cut \n",
    "\n",
    "# variables to include in the LIM (note \"vars\" is a Python command)\n",
    "#limvars = ['tas','zg']\n",
    "#limvars = ['tas','rlut','zg']\n",
    "limvars = ['sic']\n",
    "#limvars = ['tas','sic']\n",
    "#limvars = ['tas','sic','zg','psl','pr','tos']\n",
    "#limvars = ['tas','psl','tos','sit','sic']\n",
    "# limvars = ['tas','tos','psl','sit','sic']\n",
    "# limvars_nosic = ['tas','tos','psl','sit']\n",
    "#limvars = ['tas','tos','psl','sit','sic']\n",
    "#limvars = ['tas','tos','sic']\n",
    "#limvars_nosic = ['tas','tos']\n",
    "limvars_nosic = []\n",
    "nvars = len(limvars)\n",
    "\n",
    "# specify the model source \n",
    "#train_dsource = 'ccsm4_hist_kb'\n",
    "#train_dsource = 'mpi_hist_kb'\n",
    "train_dsource1 = 'cesm_lme_lm_01'\n",
    "\n",
    "train_dsource2 = 'cesm_lme_lm_02'\n",
    "\n",
    "sic_separate = True\n",
    "Insamp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from os/mkb22/Documents/SeaIceData/LME/areacello_global_LME_01.nc\n"
     ]
    }
   ],
   "source": [
    "infile_20cr_tas = '/home/disk/kalman3/rtardif/LMR/data/model/20cr/tas_sfc_Amon_20CR_185101-201112.nc'\n",
    "\n",
    "fdic_train1 = limkb.build_training_dic(train_dsource1)\n",
    "fdic_train2 = limkb.build_training_dic(train_dsource2)\n",
    "#fdic_valid = limkb.build_training_dic(valid_dsource)\n",
    "\n",
    "full_names, areawt_name, month_names = limbuild.load_full_names()\n",
    "areacell, areacell_dict = limbuild.load_areacell_dict(fdic_train1, remove_climo=False, \n",
    "                                                      detrend=False, verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing units of ds1 sic be a between 0 to 1\n",
      "Changing units of ds2 sic be a between 0 to 1\n",
      "changing cellarea units from centimeter^2 to km^2\n",
      "truncating to 50\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.0 GiB for an array with shape (122880, 24000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-53bbc2534a9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m      \u001b[0mvar_expl_by_retained\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimkb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep1_compress_individual_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmodes_sic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                                                  \u001b[0mvar_dict1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mareawt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macell_1d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                                                   wt=wt, sic_separate=True)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/si_analysis_kb/LIMs/SI_LIMs/LIM_utils_kb.py\u001b[0m in \u001b[0;36mstep1_compress_individual_var\u001b[0;34m(X_train, var, ntrunc, nmodes_sic, var_dict, areawt, wt, sic_separate)\u001b[0m\n\u001b[1;32m    836\u001b[0m          \u001b[0mtot_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_var_eig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m          \u001b[0mvar_expl_by_retained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meof_decomp_1var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'var_ndof'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                                                     X_train.shape[1],trunc,areawt=areawt,Weight=wt)\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0mW_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/si_analysis_kb/LIMs/SI_LIMs/LIM_utils_kb.py\u001b[0m in \u001b[0;36meof_decomp_1var\u001b[0;34m(X, ndof, ntime, ntrunc, areawt, Weight)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mareawt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnan_to_num\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/disk/chaos/mkb22/anaconda2/envs/lims/lib/python3.6/site-packages/numpy/lib/type_check.py\u001b[0m in \u001b[0;36mnan_to_num\u001b[0;34m(x, copy, nan, posinf, neginf)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m222222.\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m111111.j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m111111.\u001b[0m     \u001b[0;34m+\u001b[0m\u001b[0;36m0.j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m111111.\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m222222.j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \"\"\"\n\u001b[0;32m--> 461\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0mxtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 22.0 GiB for an array with shape (122880, 24000) and data type float64"
     ]
    }
   ],
   "source": [
    "wt=True\n",
    "# var_dict1 = {}\n",
    "# var_dict2 = {}\n",
    "\n",
    "for k, var in enumerate(limvars):\n",
    "#     X_var1, var_dict1 = limkb.load_data(var, var_dict1, fdic_train1, remove_climo=True, \n",
    "#                                       detrend=True, atol=False, verbose=True, cmip6=False, \n",
    "#                                       tscut=tscut1, tecut=tecut1)\n",
    "    \n",
    "#     X_var2, var_dict2 = limkb.load_data(var, var_dict2, fdic_train2, remove_climo=True, \n",
    "#                                         detrend=True, atol=False, verbose=True, cmip6=False, \n",
    "#                                         tscut=tscut2, tecut=tecut2)\n",
    "    \n",
    "    if var is 'sic':\n",
    "        if np.nanmax(X_var1)>1:\n",
    "            print('Changing units of ds1 sic be a between 0 to 1')\n",
    "            X_var1 = X_var1/100\n",
    "        if np.nanmax(X_var2)>1:\n",
    "            print('Changing units of ds2 sic be a between 0 to 1')\n",
    "            X_var2 = X_var2/100\n",
    "    \n",
    "    X_var = np.concatenate((X_var1,X_var2),axis=1)\n",
    "    \n",
    "    tsamp = X_var.shape[1]\n",
    "    \n",
    "    acell = areacell[areawt_name[var]]\n",
    "    if len(acell.shape)>1:\n",
    "        acell_1d = np.reshape(acell,(acell.shape[0]*acell.shape[1]))\n",
    "    else: \n",
    "        acell_1d = acell\n",
    "        \n",
    "    if 'km' in areacell_dict[areawt_name[var]][areawt_name[var]]['units']:\n",
    "        acell_1d = acell_1d\n",
    "    else: \n",
    "        print('changing cellarea units from '+\n",
    "              str(areacell_dict[areawt_name[var]][areawt_name[var]]['units'])+' to km^2')\n",
    "        acell_1d = acell_1d/(1000*1000)\n",
    "     \n",
    "    [Ptrunc, E3, tot_var,\n",
    "     tot_var_eig, W_all, \n",
    "     standard_factor,\n",
    "     var_expl_by_retained] = limkb.step1_compress_individual_var(X_var, var, ntrunc, nmodes_sic, \n",
    "                                                                 var_dict1, areawt=acell_1d,\n",
    "                                                                  wt=wt, sic_separate=True)\n",
    "    \n",
    "    v = {}\n",
    "    var_dict = {}\n",
    "    v['lat'] = var_dict1[var]['lat']\n",
    "    v['lon'] = var_dict1[var]['lon']\n",
    "    v['var_ndof'] = var_dict1[var]['var_ndof']\n",
    "    v['time'] = np.concatenate((var_dict1[var]['time'], var_dict2[var]['time']))\n",
    "    v['climo'] = np.concatenate((var_dict1[var]['climo'], var_dict2[var]['climo']))\n",
    "\n",
    "    var_dict[var] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data_trunc = {}\n",
    "\n",
    "mod_data_trunc['var_dict1'] = var_dict1\n",
    "mod_data_trunc['var_dict2'] = var_dict2\n",
    "mod_data_trunc['var_dict'] = var_dict\n",
    "\n",
    "mod_data_trunc['Ptrunc'] = Ptrunc\n",
    "mod_data_trunc['E3'] = E3\n",
    "mod_data_trunc['standard_factor'] = standard_factor\n",
    "mod_data_trunc['W_all'] = W_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'datetime64' in str(type(var_dict[var]['time'][0])):\n",
    "    start_yr = str(var_dict[var]['time'][0].astype('M8[Y]'))\n",
    "    end_yr = str(var_dict[var]['time'][-1].astype('M8[Y]'))\n",
    "else: \n",
    "    start_yr = str(var_dict[var]['time'][0].year)\n",
    "    end_yr = str(var_dict[var]['time'][-1].year)\n",
    "\n",
    "mod_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/truncated_model_data/'\n",
    "\n",
    "if var is 'sic':\n",
    "    nmod = nmodes_sic\n",
    "else: \n",
    "    nmod = nmodes\n",
    "    \n",
    "mod_filename = (var+'_ntrunc'+str(nmod)+'_month'+str(mo)+'_'+str(train_dsource1)+'_'+str(train_dsource2)[-6:]+\n",
    "                '_ntrain_'+start_yr+'_'+end_yr+'_'+today_date+'.pkl')\n",
    "\n",
    "print('would save in: '+mod_folder+mod_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving in: '+mod_folder+mod_filename)\n",
    "pickle.dump(mod_data_trunc, open(mod_folder+mod_filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
