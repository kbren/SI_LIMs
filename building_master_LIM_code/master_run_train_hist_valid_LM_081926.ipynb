{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy as spy\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as timestamp \n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/\")\n",
    "import LIM_utils as lim\n",
    "\n",
    "import LIM_utils_kb as limkb\n",
    "import LIM_stats_kb as statskb\n",
    "import LIM_plot_kb as plotkb\n",
    "import LIM_building as limbuild\n",
    "\n",
    "sys.path.append(\"/home/disk/kalman2/mkb22/pyLMR/\")\n",
    "import LMR_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------\n",
    "# START USER PARAMETERS\n",
    "#--------------------------------------------------\n",
    "# number of EOFs to retain for the LIM state vector\n",
    "ntrunc = 30 # EOF truncation for individual fields (reduced-state space)\n",
    "nmodes = 30 # number of coupled EOFs for LIM state space (truncated-state space)\n",
    "#nmodes = 25\n",
    "nmodes_sic = 50\n",
    "#modes_sic = 20\n",
    "\n",
    "mo='all'\n",
    "#mo=0\n",
    "\n",
    "# forecast lead time in months that defines the LIM training\n",
    "tau = 1\n",
    "\n",
    "# training data defined by the first ntrain times\n",
    "# fraction of years used in training\n",
    "# ensures that start year of both train and validation data is january\n",
    "# nyearstrain = 30\n",
    "# ntrain = int(nyearstrain*12)\n",
    "# nvalid = int(38*12)\n",
    "# nyearsvalid = 38-nyearstrain\n",
    "# nvalidtimes = 1872\n",
    "\n",
    "# variables to include in the LIM (note \"vars\" is a Python command)\n",
    "#limvars = ['tas','zg']\n",
    "#limvars = ['tas','rlut','zg']\n",
    "#limvars = ['sic']\n",
    "#limvars = ['tas','sic']\n",
    "#limvars = ['tas','sic','zg','psl','pr','tos']\n",
    "#limvars = ['tas','psl','tos','sit','sic']\n",
    "# limvars = ['tas','tos','psl','sit','sic']\n",
    "# limvars_nosic = ['tas','tos','psl','sit']\n",
    "limvars = ['tas','tos','psl','sic']\n",
    "#limvars = ['sic']\n",
    "limvars_nosic = []\n",
    "nvars = len(limvars)\n",
    "\n",
    "# specify the model source \n",
    "#train_dsource = 'satellite'\n",
    "train_dsource = 'era5'\n",
    "#train_dsource = 'mpi_hist_kb'\n",
    "#train_dsource = 'ccsm4_lm_kb'\n",
    "#valid_dsource = 'satellite'\n",
    "#valid_dsource = 'cmip6_mpi_hist'\n",
    "#valid_dsource = 'ccsm4_lm_kb'\n",
    "valid_dsource = 'cmip6_mpi_hist'\n",
    "#valid_dsource = 'mpi_lm_kb'\n",
    "#valid_dsource = 'ccsm4_lm_kb'\n",
    "\n",
    "sic_separate = True\n",
    "Insamp = False\n",
    "\n",
    "date_of_interest = '202109026'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'hist_ssp585' in train_dsource: \n",
    "    folder_add = 'hist_ssp585_concatenated/'\n",
    "elif 'hist' in train_dsource: \n",
    "    folder_add = 'historical/'\n",
    "elif 'lm' in train_dsource: \n",
    "    folder_add = 'last_millennium/'\n",
    "elif 'era5' in train_dsource: \n",
    "    folder_add = 'era5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_ntrunc30_monthall_cmip6_mpi_hist_20210826_ntrain_1850_2005_standtest.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with truncated training data: \n",
    "#mod_folder = 'truncated_model_data/last_millennium/'\n",
    "mod_folder = 'truncated_model_data/'+folder_add\n",
    "#mod_filename = '_ntrunc30_mpi_lm_kb_20210503.pkl'\n",
    "#mod_filename = '_ntrunc30_monthall_ccsm4_hist_kb_20210507_ntrain1_standtest.pkl'\n",
    "# mod_filename = '_ntrunc30_monthall_mpi_hist_kb_20210507_ntrain1_standtest.pkl'\n",
    "#mod_filename = '_ntrunc'+str(ntrunc)+'_monthall_cmip6_mpi_hist_20210819_ntrain_1850_1999_standtest.pkl'\n",
    "#mod_filename = '_ntrunc'+str(ntrunc)+'_monthall_mpi_hist_kb_20210824_ntrain_1850_1999_standtest.pkl'\n",
    "mod_filename = ('_ntrunc'+str(ntrunc)+'_monthall_'+train_dsource+\n",
    "                '_ntrain_1850_2005_'+date_of_interes+'.pkl')\n",
    "\n",
    "#mod_filename = '_ntrunc30_mpi_lm_kb_20210507_ntrain0_3_standtest.pkl'\n",
    "#mod_sic_filename = '_ntrunc50_mpi_lm_kb_20210406.pkl'\n",
    "#mod_sic_filename = '_ntrunc50_monthall_ccsm4_hist_kb_20210507_ntrain1_standtest.pkl'\n",
    "#mod_sic_filename = '_ntrunc50_monthall_mpi_hist_kb_20210507_ntrain1_standtest.pkl'\n",
    "#mod_sic_filename = '_ntrunc'+str(nmodes_sic)+'_monthall_cmip6_mpi_hist_20210819_ntrain_1850_1999_standtest.pkl'\n",
    "#mod_sic_filename = '_ntrunc'+str(nmodes_sic)+'_monthall_mpi_hist_kb_20210824_ntrain_1850_1999_standtest.pkl'\n",
    "mod_sic_filename = ('_ntrunc'+str(ntrunc)+'_monthall_'+train_dsource+\n",
    "                    '_ntrain_1850_2005_'+date_of_interes+'.pkl')\n",
    "\n",
    "\n",
    "\n",
    "#mod_sic_filename = '_ntrunc50_month0_mpi_hist_kb_20210727_ntrain1_standtest.pkl'\n",
    "#mod_sic_filename = '_ntrunc50_mpi_lm_kb_20210507_ntrain0_3_standtest.pkl'\n",
    "mod_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1850_2005'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_filename[-23:-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_setup = {}\n",
    "exp_setup['mo'] = mo\n",
    "exp_setup['tau'] = tau\n",
    "exp_setup['ntrunc'] = ntrunc \n",
    "exp_setup['nmodes_sic'] = nmodes_sic\n",
    "exp_setup['limvars'] = limvars\n",
    "exp_setup['train_dsource'] = train_dsource\n",
    "exp_setup['valid_dsource'] = valid_dsource \n",
    "exp_setup['sic_separate'] = sic_separate\n",
    "exp_setup['Insamp'] = Insamp\n",
    "exp_setup['mod_folder'] = mod_folder\n",
    "exp_setup['mod_filename'] = mod_filename\n",
    "exp_setup['mod_sic_filename'] = mod_sic_filename\n",
    "exp_setup['nyearsvalid'] = 100\n",
    "#exp_setup['nyearstot'] = 156\n",
    "exp_setup['nyearstot'] = 155\n",
    "exp_setup['nyears_startvalid'] = 0\n",
    "exp_setup['ntrain']=((exp_setup['nyearstot']*12)-(exp_setup['nyearsvalid'] *12))/(exp_setup['nyearstot']*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_names = ['Jan','Feb','Mar','Apr','May','June','July','Aug','Sept','Oct','Nov','Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_forecast_model_data as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'LIM_utils_kb' from '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIM_utils_kb.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rf)\n",
    "importlib.reload(limbuild)\n",
    "importlib.reload(limkb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from torical/areacella_fx_MPI-ESM1-2-LR_historical_r1i1p1f1_gn.nc\n",
      "Loading from orical/areacello_Ofx_MPI-ESM1-2-LR_historical_r1i1p1f1_gn.nc\n",
      "Loading truncated tas\n",
      "Loading truncated tos\n",
      "Loading truncated sit\n",
      "Loading truncated sic\n",
      "working on tas\n",
      "working on tos\n",
      "working on sit\n",
      "working on sic\n",
      "0, tas\n",
      "1, tos\n",
      "2, sit\n",
      "Training LIM with tau = 1\n",
      "Number of positive eigenvalues = 0.0\n",
      "saving in: /home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/L_cmip6_mpi_hist_ntrain_1850_2005_tas30_tos30_sit30_sic50_20210902.pkl\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------\n",
    "### Build L from truncated data: \n",
    "#--------------------------------------------------\n",
    "\n",
    "save_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "\n",
    "LIMd = rf.build_L(exp_setup, save_folder, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... L_cmip6_mpi_hist_ntrain_1850_2005_tas30_tos30_sit30_sic50_20210902.pkl\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------\n",
    "### Load pre-build L: \n",
    "#--------------------------------------------------\n",
    "date_of_interest = '20210902'\n",
    "L_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "#L_filename = 'L_'+train_dsource+'_ntrain_1850_2004_tas30_tos30_sit30_sic50_'+date_of_interest+'.pkl'\n",
    "L_filename = 'L_'+train_dsource+'_ntrain_'+mod_filename[-23:-14]+'_tas30_tos30_sit30_sic50_'+date_of_interest+'.pkl'\n",
    "print('Loading... '+L_filename)\n",
    "\n",
    "LIMd = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18432,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIMd['W_all']['tas'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Forecast: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [0,1,2,3,4,5,6]\n",
    "\n",
    "if LIMd['npos_eigenvalues'] >0: \n",
    "    adj = True\n",
    "else: \n",
    "    adj = False\n",
    "\n",
    "exp_setup['lags'] = lags\n",
    "exp_setup['adj'] = adj\n",
    "exp_setup['remove_climo'] = True\n",
    "exp_setup['detrend'] = True\n",
    "exp_setup['nyr_train'] = None\n",
    "exp_setup['Insamp'] = Insamp\n",
    "\n",
    "f_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data: cmip6_cesm2_hist\n",
      "Loading from tas\n",
      "Loading from rical/tas_Amon_CESM2_historical_r1i1p1f1_gn_185001-201412.nc\n",
      "time dimension: 1850 - 1959\n",
      "(1320,)\n",
      "removing climotology...\n",
      "detrending...\n",
      "(55296, 1320)\n",
      "(55296, 1320)\n",
      "-----------------------------------------------------\n",
      "completed in 7.640288829803467 seconds\n",
      "-----------------------------------------------------\n",
      "Validation shape: (55296, 1320)\n",
      "from 1850 thru 1959\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (18432,1) (55296,1320) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-281d846ba868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLIMd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_setup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/si_analysis_kb/LIMs/SI_LIMs/run_forecast_model_data.py\u001b[0m in \u001b[0;36mrun_forecast\u001b[0;34m(LIMd, exp_setup, f_folder, verbose, save, save_decomp)\u001b[0m\n\u001b[1;32m    144\u001b[0m         Ptrunc_valid[var] = limkb.step1_projection_validation_var(X_var_valid, LIMd['E3'][var], \n\u001b[1;32m    145\u001b[0m                                                                   \u001b[0mLIMd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'standard_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                                                                   LIMd['W_all'][var])\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mvar_dict_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimbuild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_var_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_setup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'limvars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dict_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/si_analysis_kb/LIMs/SI_LIMs/LIM_utils_kb.py\u001b[0m in \u001b[0;36mstep1_projection_validation_var\u001b[0;34m(X_train, E3, standard_factor, W)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0meofs_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstandard_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;31m# projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0mP_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meofs_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW_new\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0mPtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP_var\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstandard_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18432,1) (55296,1320) "
     ]
    }
   ],
   "source": [
    "forecast = rf.run_forecast(LIMd,exp_setup, f_folder, verbose=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "# L_filename = 'Forecast_'+train_dsource+'_ntrain_1850_2005_tas30_tos30_sit30_sic50_'+date_of_interest+'.pkl'\n",
    "\n",
    "# forecast = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data: cmip6_cesm2_hist\n",
      "Loading from tas\n",
      "Loading from rical/tas_Amon_CESM2_historical_r1i1p1f1_gn_185001-201412.nc\n",
      "time dimension: 1850 - 1959\n",
      "(1320,)\n",
      "removing climotology...\n",
      "detrending...\n",
      "(55296, 1320)\n",
      "(55296, 1320)\n",
      "-----------------------------------------------------\n",
      "completed in 7.630411624908447 seconds\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "fdic_valid = limkb.build_training_dic(exp_setup['valid_dsource'])\n",
    "\n",
    "Ptrunc_valid = {}\n",
    "var_dict_valid = {}\n",
    "ntims = len(exp_setup['lags'])\n",
    "print('Validation data: '+exp_setup['valid_dsource'])\n",
    "verbose=True\n",
    "\n",
    "for k, var in enumerate(['tas']): \n",
    "    tecut = exp_setup['nyears_startvalid']+exp_setup['nyearstot']-exp_setup['nyearsvalid']\n",
    "    X_var_valid, var_dict_valid = limkb.load_data(var, var_dict_valid, fdic_valid, remove_climo=exp_setup['remove_climo'], \n",
    "                                            detrend=exp_setup['detrend'], verbose=verbose, \n",
    "                                            tscut=exp_setup['nyears_startvalid'], tecut=tecut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55296, 1320), (18432,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var_valid.shape, LIMd['W_all']['tas'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_validation = rf.validate_forecast_monthly(forecast, exp_setup['limvars'], 1, exp_setup, LIMd, f_folder, \n",
    "                                                   iplot=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # L_filename = ('Forecast_validation_'+train_dsource+\n",
    "# #               '_ntrain_1850_2005_validation_'+valid_dsource+'_0_100_tas30_tos30_sit30_sic50_'+\n",
    "# #               date_of_interest+'.pkl')\n",
    "\n",
    "# L_filename = 'Forecast_validation_mpi_hist_kb_ntrain_1850_2005_tas30_tos30_sit30_sic50_20210826.pkl'\n",
    "# print('Opening...'+ L_filename)\n",
    "\n",
    "# forecast_validation_monthly = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_validation_lags = rf.validate_forecast_lagged(forecast, exp_setup['limvars'], exp_setup, LIMd, \n",
    "                                                       f_folder, iplot=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # L_filename = ('Forecast_validation_lagged_'+train_dsource+\n",
    "# #               '_ntrain_1850_2005_validation_'+valid_dsource+'_0_100_tas30_tos30_sit30_sic50_'+\n",
    "# #               date_of_interest+'.pkl')\n",
    "\n",
    "# L_filename = 'Forecast_validation_lagged_mpi_hist_kb_ntrain_1850_2005_tas30_tos30_sit30_sic50_20210826.pkl'\n",
    "# print('Opening...'+ L_filename)\n",
    "\n",
    "# forecast_validation_lags = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AR1 Forecast: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_vars=limvars\n",
    "ar1f_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "\n",
    "ar1cast = rf.ar1_forecast_valid_by_month(LIMd['P_train'], forecast['P_train_valid'], LIMd,\n",
    "                                         exp_setup, valid_vars, month_names, ar1f_folder, forecast,  \n",
    "                                         lag=None, iplot=True, save=True, save_decomp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "# # L_filename = ('AR1_forecast_monthly_'+train_dsource+\n",
    "# #               '_ntrain_1850_1999_tas30_tos30_psl30_sit30_sic50_'+date_of_interest+'.pkl')\n",
    "\n",
    "# L_filename = ('AR1_forecast_monthly_'+train_dsource+'__ntrain_1850_2005_validation_'+\n",
    "#               valid_dscource+'_'+exp_setup['nyears_startvalid']+'_'+exp_setup['nyearsvalid']+\n",
    "#               '_tas30_tos30_sit30_sic50_'+date_of_interest+'.pkl')\n",
    "# print('Opening...'+L_filename)\n",
    "\n",
    "# ar1cast = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ar1f_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "\n",
    "ar1cast_lags = rf.ar1_forecast_valid_by_lag(LIMd['P_train'], forecast['P_train_valid'], LIMd, exp_setup, \n",
    "                                            exp_setup['limvars'], month_names, ar1f_folder, forecast, \n",
    "                                            iplot=True, save=True, save_decomp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "# # L_filename = ('AR1_forecast_lagged_'+train_dsource+\n",
    "# #               '_ntrain_1850_1999_tas30_tos30_psl30_sit30_sic50_'+date_of_interest+'.pkl')\n",
    "\n",
    "# L_filename = ('AR1_forecast_lagged_'+train_dsource+'__ntrain_1850_2005_validation_'+\n",
    "#               valid_dscource+'_'+exp_setup['nyears_startvalid']+'_'+exp_setup['nyearsvalid']+\n",
    "#               '_tas30_tos30_sit30_sic50_'+date_of_interest+'.pkl')\n",
    "# print('Opening...'+L_filename\n",
    "\n",
    "# ar1cast_lags = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import date\n",
    "\n",
    "# today = date.today()\n",
    "\n",
    "# #Year-month-day\n",
    "# today_date = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "# ar1_validation = {}\n",
    "\n",
    "# ar1_validation['validation_stats_ar1_lags'] = ar1cast_lags['validation_stats_ar1_lags']\n",
    "# ar1_validation['validation_stats_ar1'] = ar1cast['validation_stats_ar1']\n",
    "\n",
    "# ar1f_filename = ('AR1_validation_all_'+exp_setup['valid_dsource']+'_'+\n",
    "#                 str(exp_setup['nyears_startvalid'])+'_'+str(exp_setup['nyearsvalid'])+'_'+\n",
    "#                 (str(exp_setup['ntrunc'])+\"_\").join(exp_setup['limvars'])+\n",
    "#                 str(exp_setup['nmodes_sic'])+'_'+today_date+'.pkl')\n",
    "\n",
    "# print('saving in: '+ar1f_folder+ar1f_filename)\n",
    "# pickle.dump(ar1_validation, open(ar1f_folder+ar1f_filename, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_folder = '/home/disk/p/mkb22/Documents/si_analysis_kb/LIMs/SI_LIMs/LIMs_saved/'\n",
    "# L_filename = ('AR1_validation_all_mpi_lm_kb_0_100_tas30_tos30_sit30_sic50_20210826.pkl')\n",
    "\n",
    "# ar1_validation = pickle.load(open(L_folder+L_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation by lag: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cmip6' in train_dsource: \n",
    "    tcmip='CMIP6'\n",
    "else: \n",
    "    tcmip='CMIP5'\n",
    "\n",
    "var = 'sic'\n",
    "# start_tim = exp_setup['nyears_startvalid']\n",
    "# end_tim = exp_setup['nyears_startvalid']+(exp_setup['nyearsvalid']*12)\n",
    "valid_yrs_str = (str(forecast['var_dict_valid'][var]['time'][0])[:4]+'_'+\n",
    "                 str(forecast['var_dict_valid'][var]['time'][-1])[:4])\n",
    "\n",
    "if 'hist' in train_dsource:\n",
    "    texp = 'Historical'\n",
    "elif 'lm' in train_dsource: \n",
    "    texp = 'LM'\n",
    "elif 'ssp585' in train_dsource: \n",
    "    texp = 'SSP585'\n",
    "    \n",
    "if 'hist' in valid_dsource:\n",
    "    vexp = 'Historical'\n",
    "elif 'lm' in valid_dsource: \n",
    "    vexp = 'LM'\n",
    "elif 'ssp585' in valid_dsource: \n",
    "    vexp = 'SSP585'\n",
    "    \n",
    "if 'cesm2' in train_dsource:\n",
    "    tmod = 'CESM2'\n",
    "elif 'mpi' in train_dsource: \n",
    "    tmod = 'MPI'\n",
    "elif 'gfdl' in train_dsource: \n",
    "    tmod = 'GFDL'\n",
    "elif 'ccsm4' in train_dsource: \n",
    "    tmod = 'CCSM4'\n",
    "    \n",
    "if 'cesm2' in valid_dsource:\n",
    "    vmod = 'CESM2'\n",
    "elif 'mpi' in valid_dsource: \n",
    "    vmod = 'MPI'\n",
    "elif 'gfdl' in valid_dsource: \n",
    "    vmod = 'GFDL'\n",
    "elif 'ccsm4' in valid_dsource: \n",
    "    vmod = 'CCSM4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,3,figsize=(20,10))\n",
    "#fig,axs= plt.subplots(2, 2)\n",
    "\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i,var in enumerate(exp_setup['limvars']):\n",
    "    ax[i].plot(exp_setup['lags'][1:],forecast_validation_lags['validation_stats_lags'][var]['corr_tot'][1:]**2, \n",
    "               label='Correlation',linewidth=4)\n",
    "    ax[i].plot(exp_setup['lags'][1:],ar1cast_lags['validation_stats_ar1_lags'][var]['corr_tot'][:-1]**2, \n",
    "               label='AR(1) Correlation',linewidth=4, \n",
    "               linestyle='--', color='tab:blue',alpha=0.5)\n",
    "\n",
    "    ax[i].plot(exp_setup['lags'][1:],forecast_validation_lags['validation_stats_lags'][var]['ce_tot'][1:],\n",
    "               label='CE',linewidth=3.0)\n",
    "    ax[i].plot(exp_setup['lags'][1:],ar1cast_lags['validation_stats_ar1_lags'][var]['ce_tot'][:-1],\n",
    "               label='AR(1) CE',linewidth=3.0, \n",
    "               linestyle='--', color='tab:orange', alpha=0.5)\n",
    "\n",
    "    ax[i].set_xticks(np.arange(0,11,1))\n",
    "    ax[i].set_xticklabels(np.arange(0,11,1),fontsize=12)\n",
    "    ax[i].set_ylim(0,1)\n",
    "    ax[i].set_xlim(1,len(exp_setup['lags'][1:]))\n",
    "    ax[i].grid(axis='both')\n",
    "    ax[i].set_title(var, fontsize=14)\n",
    "#    ax[i].text(0.1,0.05, (\"Mean R$^2$ = \"+str(np.round(np.mean(validation_stats[var]['corr_tot']**2),2))),fontsize=14)\n",
    "    \n",
    "if Insamp==True:     \n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+str(int(850+ntrain*1000))+\n",
    "                 ', Validation years: Historical'), fontsize=16)\n",
    "else: \n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+tcmip+' '+tmod+' '+texp+' '+\n",
    "                  exp_setup['mod_filename'][-23:-14]+', Validation years: '+vmod+' '+vexp+' '+\n",
    "                  valid_yrs_str), fontsize=16)\n",
    "\n",
    "# ax[i].text(0.1,0.05, (\"Training years: \"+str(850)+'-'+str(850+ntrain*1000)),fontsize=14)\n",
    "# ax[i].text(0.1,0.05, (\"Validation years: \"+str(850+ntrain*1000)+'-1850'),fontsize=14)\n",
    "\n",
    "\n",
    "ax[1].legend(loc='lower left', fontsize=14)\n",
    "ax[2].set_xlabel('Lag (months)', fontsize=14)\n",
    "ax[1].set_xlabel('Lag (months)', fontsize=14)\n",
    "ax[3].set_xlabel('Lag (months)', fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,3,figsize=(20,10))\n",
    "#fig,axs= plt.subplots(2, 2)\n",
    "\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i,var in enumerate(exp_setup['limvars']):\n",
    "    ax[i].plot(exp_setup['lags'][1:],forecast_validation_lags['validation_stats_lags'][var]['gm_var_ratio'][1:], \n",
    "               label='LIM',linewidth=3.0, color='purple')\n",
    "    ax[i].plot(exp_setup['lags'][1:],ar1cast_lags['validation_stats_ar1_lags'][var]['gm_var_ratio'][:-1], \n",
    "               label='AR(1)',linewidth=3.0, linestyle='--', color='purple',alpha=0.5)\n",
    "\n",
    "    ax[i].set_xticks(np.arange(0,11,1))\n",
    "    ax[i].set_xticklabels(np.arange(0,11,1),fontsize=12)\n",
    "    ax[i].set_ylim(0,1.1)\n",
    "    ax[i].set_xlim(1,len(exp_setup['lags'][1:]))\n",
    "    ax[i].grid(axis='both')\n",
    "    ax[i].set_title(var, fontsize=14)\n",
    "    \n",
    "    ax[i].axhline(1.0, color='k', linewidth=2, label='No skill')\n",
    "    \n",
    "if Insamp==True:     \n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+str(int(850+ntrain*1000))+\n",
    "                 ', Validation years: Historical'), fontsize=16)\n",
    "else:     \n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+tcmip+' '+tmod+' '+texp+' '+\n",
    "                  exp_setup['mod_filename'][-23:-14]+', Validation years: '+vmod+' '+vexp+' '+\n",
    "                  valid_yrs_str), fontsize=16)\n",
    "\n",
    "# ax[i].text(0.1,0.05, (\"Training years: \"+str(850)+'-'+str(850+ntrain*1000)),fontsize=14)\n",
    "# ax[i].text(0.1,0.05, (\"Validation years: \"+str(850+ntrain*1000)+'-1850'),fontsize=14)\n",
    "\n",
    "\n",
    "ax[1].legend(loc='lower right', fontsize=14)\n",
    "ax[2].set_xlabel('Lag (months)', fontsize=14)\n",
    "ax[1].set_xlabel('Lag (months)', fontsize=14)\n",
    "ax[3].set_xlabel('Lag (months)', fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation by month: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,3,figsize=(20,9))\n",
    "#fig,axs= plt.subplots(2, 2)\n",
    "\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i,var in enumerate(exp_setup['limvars']):\n",
    "    ax[i].plot(forecast_validation['validation_stats'][var]['corr_tot']**2, label='Correlation',linewidth=3.0)\n",
    "    ax[i].plot(ar1cast['validation_stats_ar1'][var]['corr_tot']**2, label='AR(1) Correlation',linewidth=3.0, \n",
    "               linestyle='--', color='tab:blue',alpha=0.5)\n",
    "\n",
    "    ax[i].plot(forecast_validation['validation_stats'][var]['ce_tot'],label='CE',linewidth=3.0)\n",
    "    ax[i].plot(ar1cast['validation_stats_ar1'][var]['ce_tot'],label='AR(1) CE',linewidth=3.0, \n",
    "               linestyle='--', color='tab:orange', alpha=0.5)\n",
    "\n",
    "    ax[i].set_ylim(0,1)\n",
    "#     ax[i].set_xlim(0,10)\n",
    "    ax[i].set_xticks(np.arange(0,11,1))\n",
    "    ax[i].set_xticklabels(month_names,fontsize=12)#, rotation=45)\n",
    "    ax[i].grid(axis='both')\n",
    "    ax[i].set_title(var, fontsize=14)\n",
    "    mn = np.round(np.mean(forecast_validation['validation_stats'][var]['corr_tot']**2),2)\n",
    "    ax[i].text(0.1,0.05, (\"Mean R$^2$ = \"+str(mn)),fontsize=14)\n",
    "\n",
    "if Insamp==True:     \n",
    "#     plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+str(int(850+ntrain*1000))+\n",
    "# #                  ', Validation years: Historical'+str(850)+'-'+str(int(850+ntrain*1000))), fontsize=16)\n",
    "    plt.suptitle('None')\n",
    "else:     \n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+tcmip+' '+tmod+' '+texp+' '+\n",
    "                  exp_setup['mod_filename'][-23:-14]+', Validation years: '+vmod+' '+vexp+' '+\n",
    "                  valid_yrs_str), fontsize=16)\n",
    "\n",
    "# ax[i].text(0.1,0.05, (\"Training years: \"+str(850)+'-'+str(850+ntrain*1000)),fontsize=14)\n",
    "# ax[i].text(0.1,0.05, (\"Validation years: \"+str(850+ntrain*1000)+'-1850'),fontsize=14)\n",
    "\n",
    "\n",
    "ax[1].legend(loc='lower right', fontsize=14)\n",
    "ax[2].set_xlabel('Forecasted month', fontsize=14)\n",
    "ax[4].set_xlabel('Forecasted month', fontsize=14)\n",
    "ax[3].set_xlabel('Forecasted month', fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,3,figsize=(20,10))\n",
    "#fig,axs= plt.subplots(2, 2)\n",
    "\n",
    "ax = axs.flatten()\n",
    "\n",
    "for i,var in enumerate(limvars):\n",
    "    ax[i].plot(forecast_validation['validation_stats'][var]['gm_var_ratio'],linewidth=3.0, color='purple')\n",
    "\n",
    "    ax[i].plot(ar1cast['validation_stats_ar1'][var]['gm_var_ratio'],linewidth=3.0, color='purple', \n",
    "               linestyle='--', alpha=0.5)\n",
    "\n",
    "#    ax[i].set_ylim(0,1)\n",
    "    ax[i].set_xlim(0,10)\n",
    "    ax[i].set_ylim(0,1.1)\n",
    "    ax[i].set_xticks(np.arange(0,11,1))\n",
    "    ax[i].set_xticklabels(month_names,fontsize=12)\n",
    "    ax[i].grid(axis='both')\n",
    "    ax[i].set_title(var, fontsize=16)\n",
    "    ax[i].text(0.15,0.05, (\"Mean ratio = \"+str(np.round(np.mean(forecast_validation['validation_stats'][var]['gm_var_ratio']),2))),\n",
    "               fontsize=14)\n",
    "    ax[i].axhline(1.0,color='k',linestyle='--')\n",
    "\n",
    "if Insamp==True:     \n",
    "#     plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+str(int(850+ntrain*1000))+\n",
    "#                  ', Validation years: Historical'+str(850)+'-'+str(int(850+ntrain*1000))), fontsize=16)\n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+str(int(850+ntrain*1000))+\n",
    "                 ', Validation years: Historical'), fontsize=16)\n",
    "else:     \n",
    "#     plt.suptitle(('LIM trained on all months \\n Training years: '+str(850)+'-'+\n",
    "#                   str(int(850+ntrain*1000))+', Validation years: '+\n",
    "#                   str(int(850+ntrain*1000))+'-'+str(int(850+ntrain*1000+nvalidtimes/12))), fontsize=16)\n",
    "    plt.suptitle(('LIM trained on all months \\n Training years: '+tcmip+' '+tmod+' '+texp+' '+\n",
    "                  exp_setup['mod_filename'][-23:-14]+', Validation years: '+vmod+' '+vexp+' '+\n",
    "                  valid_yrs_str), fontsize=16)\n",
    "    \n",
    "ax[2].set_xlabel('Forecasted month', fontsize=14)\n",
    "ax[1].set_xlabel('Forecasted month', fontsize=14)\n",
    "ax[3].set_xlabel('Forecasted month', fontsize=14)\n",
    "ax[0].set_ylabel('GM ratio: \\nerror variance to true variance', fontsize=14)\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
